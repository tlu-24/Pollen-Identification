{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code adapted from Professor Wloka from CS153 transfer_learning demo\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [16, 10]\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.RandomHorizontalFlip(), # randomly flip with a 0.5 chance\n",
    "        transforms.RandomVerticalFlip(), # randomly flip with a 0.5 chance\n",
    "        #randomly change the brightness with a max of 0.5 and the hue with a range of -.4 to .4\n",
    "        transforms.ColorJitter(0.05, 0, 0,(-0.4, 0.4)), \n",
    "        transforms.RandomGrayscale(0.2), # randomly change image to grayscale with a 0.2 chance\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'project_data_c'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "#creates a txt file with all of the different classes\n",
    "with open(\"class_names.txt\", 'w') as f:\n",
    "    for classes in class_names:\n",
    "        f.write(str(classes) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_show(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "tensor_show(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    nb_classes = len(class_names)\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            running_corrects_top3 = 0\n",
    "            #creates a confusion matrix\n",
    "            confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                labels = labels.to(device)\n",
    "                inputs = inputs.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs.float())\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)  \n",
    "                    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                #calculates top 3 accuracies credit to weiaicunzai github:https://gist.github.com/weiaicunzai/2a5ae6eac6712c70bde0630f3e76b77b\n",
    "                maxk = 3  # labels that we will consider correct\n",
    "                _, y_pred = outputs.topk(k=maxk, dim=1)\n",
    "                y_pred = y_pred.t()\n",
    "                target_reshaped = labels.view(1, -1).expand_as(y_pred)\n",
    "                correct = (y_pred == target_reshaped)\n",
    "                # get tensor of which topk answer was right\n",
    "                ind_which_topk_matched_truth = correct[:3]\n",
    "                # flatten it to help compute if we got it correct for each example in batch\n",
    "                flattened_indicator_which_topk_matched_truth = ind_which_topk_matched_truth.reshape(-1).float()\n",
    "                # adds if there is a correct predicion\n",
    "                running_corrects_top3 += flattened_indicator_which_topk_matched_truth.float().sum(dim=0, keepdim=True)\n",
    "\n",
    "\n",
    "                #populate the confusion array\n",
    "                for t, p in zip(labels.view(-1), preds.view(-1)):\n",
    "                        confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            running_corrects_top3 = running_corrects_top3.numpy()\n",
    "            epoch_acc_top3 = running_corrects_top3[0] / dataset_sizes[phase]\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            tp_and_fn = confusion_matrix.sum(1)\n",
    "            tp_and_fp = confusion_matrix.sum(0)\n",
    "            tp = confusion_matrix.diagonal()\n",
    "\n",
    "            precision = tp / tp_and_fp\n",
    "            recall = tp / tp_and_fn\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} Top3 Acc: {epoch_acc_top3:.4f}')\n",
    "            print(confusion_matrix.diag()/confusion_matrix.sum(1))\n",
    "            print(f'Precision: {precision} ')\n",
    "            print(f'Recall: {recall}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_acc_top3 = epoch_acc_top3\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                best_confusion_matrix = confusion_matrix\n",
    "                best_precision = precision\n",
    "                best_recall = recall\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f} Best val Acc Top3: {best_acc_top3:.4f}')\n",
    "    print(f'Best classes Acc: {best_confusion_matrix.diag()/best_confusion_matrix.sum(1)}')\n",
    "    print(f'Best classes precision: {best_precision}')\n",
    "    print(f'Best class recall: {best_recall}')\n",
    "    print(best_confusion_matrix)\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'predicted: {class_names[preds[j]]}')\n",
    "                tensor_show(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
    "                         exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(filename):\n",
    "        \"\"\"saves the model returned from after training it\n",
    "        inputs: filename the name you want to save the model as\n",
    "        \"\"\"\n",
    "        torch.save(model_conv, filename+\".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(modelname, class_names, image):\n",
    "    \"\"\"gives the top 3 predictions of what the image is along with their Probabilities\n",
    "    input: model the location of the model you want to use,\n",
    "    class_names location of the text files of the classes the model was trained on\n",
    "    image: the location of the images you want to predict\n",
    "    \"\"\"\n",
    "\n",
    "    #transforms to be preformed on the input images\n",
    "    data_transforms = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    image = Image.open(image)\n",
    "    image = data_transforms(image)\n",
    "    image = image.unsqueeze(0)\n",
    "\n",
    "    #save the classes in the class_names into a list\n",
    "    with open(class_names, 'r') as f:\n",
    "        class_names = [line.rstrip('\\n') for line in f]\n",
    "    \n",
    "    \n",
    "    # Disable grad\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Loading the saved model\n",
    "        model = torch.load(modelname)\n",
    "        model.eval()\n",
    "        \n",
    "        outputs = model(image)\n",
    "        #find the probaility of each output\n",
    "        predicted_classes = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        predicted_classes = predicted_classes.numpy()\n",
    "        predicted_classes_unsorted = copy.deepcopy(predicted_classes)\n",
    "        #sort the array so we can find the top predictions\n",
    "        predicted_classes.sort()\n",
    "\n",
    "        top3 = []\n",
    "        #finds out what what the top 3 classes are (theres probability a simpler way to do this)\n",
    "        i = -1\n",
    "        while i != -4:\n",
    "            for j in range(len(predicted_classes[0])):\n",
    "                if predicted_classes[0][i] == predicted_classes_unsorted[0][j]:\n",
    "                    top3 += [j]\n",
    "                    break\n",
    "            i -=1\n",
    "\n",
    "        #unnormalize the image to display\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "        std = torch.tensor([0.229, 0.224, 0.225])\n",
    "        image = image *std[:, None, None] + mean[:, None, None]\n",
    "        image = image.squeeze(0)\n",
    "        image = image.T\n",
    "        image = image.numpy()\n",
    "        \n",
    "        # Show result\n",
    "        plt.imshow((image * 255).astype(np.uint8))\n",
    "        plt.title(f'Prediction: {class_names[top3[0]]} Probability: {predicted_classes[0][-1]:.4f} \\nPrediction: {class_names[top3[1]]} Probability: {predicted_classes[0][-2]:.4f} \\nPrediction: {class_names[top3[2]]} Probability: {predicted_classes[0][-3]:.4f}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
